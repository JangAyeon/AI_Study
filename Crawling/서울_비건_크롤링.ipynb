{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "서울 비건 크롤링.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbrm7Oy4PGceRC5oel6ZKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JangAyeon/TIL/blob/main/%EC%84%9C%EC%9A%B8_%EB%B9%84%EA%B1%B4_%ED%81%AC%EB%A1%A4%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4emOY__a_t"
      },
      "source": [
        "# 카카오 맵 \"서울 비건\" 크롤링\n",
        "[참고링크](https://github.com/yoonkt200/python-data-analysis/blob/master/chapter4/02-restaurant-sentiment-analysis.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZecB0dL9ROa",
        "outputId": "80b38514-406a-49b2-c659-b3ad31987659"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,365 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,431 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,210 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,801 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 11.9 MB in 4s (3,205 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 95.4 MB of archives.\n",
            "After this operation, 323 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 94.0.4606.71-0ubuntu0.18.04.1 [1,136 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 94.0.4606.71-0ubuntu0.18.04.1 [85.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 94.0.4606.71-0ubuntu0.18.04.1 [4,161 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 94.0.4606.71-0ubuntu0.18.04.1 [4,964 kB]\n",
            "Fetched 95.4 MB in 4s (23.7 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_94.0.4606.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_94.0.4606.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_94.0.4606.71-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_94.0.4606.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (94.0.4606.71-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyX_LT_99LEI"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPLlkLYd9Lvr",
        "outputId": "220357f7-37e9-45dc-d275-375b66269b2f"
      },
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "\n",
        "#setting driver for colab\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "\n",
        "# 크롤링할 사이트 주소를 정의합니다.\n",
        "source_url = \"https://map.kakao.com/\"\n",
        "\n",
        "# 크롬 드라이버를 사용합니다 (맥은 첫 줄, 윈도우는 두번째 줄 실행)\n",
        "# driver = webdriver.Chrome(path)\n",
        "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
        "\n",
        "# 카카오 지도에 접속합니다\n",
        "driver.get(source_url)\n",
        "\n",
        "# 검색창에 검색어를 입력합니다\n",
        "searchbox = driver.find_element_by_xpath(\"//input[@id='search.keyword.query']\")\n",
        "searchbox.send_keys(\"서울 비건\")\n",
        "\n",
        "# 검색버튼을 눌러서 결과를 가져옵니다\n",
        "searchbutton = driver.find_element_by_xpath(\"//button[@id='search.keyword.submit']\")\n",
        "driver.execute_script(\"arguments[0].click();\", searchbutton)\n",
        "\n",
        "# 검색 결과를 가져올 시간을 기다립니다\n",
        "time.sleep(2)\n",
        "\n",
        "# 검색 결과의 페이지 소스를 가져옵니다\n",
        "html = driver.page_source\n",
        "\n",
        "# BeautifulSoup을 이용하여 html 정보를 파싱합니다\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "moreviews = soup.find_all(name=\"a\", attrs={\"class\":\"moreview\"})\n",
        "\n",
        "# a태그의 href 속성을 리스트로 추출하여, 크롤링 할 페이지 리스트를 생성합니다.\n",
        "page_urls = []\n",
        "for moreview in moreviews:\n",
        "    page_url = moreview.get(\"href\")\n",
        "    print(page_url)\n",
        "    page_urls.append(page_url)\n",
        "\n",
        "# 크롤링에 사용한 브라우저를 종료합니다.\n",
        "driver.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://place.map.kakao.com/249361839\n",
            "https://place.map.kakao.com/1723597115\n",
            "https://place.map.kakao.com/1604705350\n",
            "https://place.map.kakao.com/2003415273\n",
            "https://place.map.kakao.com/1521847061\n",
            "https://place.map.kakao.com/540697998\n",
            "https://place.map.kakao.com/427041017\n",
            "https://place.map.kakao.com/1056076272\n",
            "https://place.map.kakao.com/1450576553\n",
            "https://place.map.kakao.com/1173919463\n",
            "https://place.map.kakao.com/15223355\n",
            "https://place.map.kakao.com/1428965358\n",
            "https://place.map.kakao.com/796480242\n",
            "https://place.map.kakao.com/12631022\n",
            "https://place.map.kakao.com/1786895224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPfQQ9r49PMy"
      },
      "source": [
        "columns = ['score', 'review']\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options) #for colab \n",
        "\n",
        "for page_url in page_urls:\n",
        "    \n",
        "    # 상세보기 페이지에 접속합니다\n",
        "    driver.get(page_url)\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # 첫 페이지 리뷰를 크롤링합니다\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    contents_div = soup.find(name=\"div\", attrs={\"class\":\"evaluation_review\"})\n",
        "    \n",
        "    # 별점을 가져옵니다.\n",
        "    rates = contents_div.find_all(name=\"em\", attrs={\"class\":\"num_rate\"})\n",
        "    \n",
        "    # 리뷰를 가져옵니다.\n",
        "    reviews = contents_div.find_all(name=\"p\", attrs={\"class\":\"txt_comment\"})\n",
        "    \n",
        "    for rate, review in zip(rates, reviews):\n",
        "        row = [rate.text[0], review.find(name=\"span\").text]\n",
        "        series = pd.Series(row, index=df.columns)\n",
        "        df = df.append(series, ignore_index=True)\n",
        "    \n",
        "    # 2-5페이지의 리뷰를 크롤링합니다\n",
        "    for button_num in range(2, 6):\n",
        "        # 오류가 나는 경우(리뷰 페이지가 없는 경우), 수행하지 않습니다.\n",
        "        try:\n",
        "            another_reviews = driver.find_element_by_xpath(\"//a[@data-page='\" + str(button_num) + \"']\")\n",
        "            another_reviews.click()\n",
        "            time.sleep(2)\n",
        "            \n",
        "            # 페이지 리뷰를 크롤링합니다\n",
        "            html = driver.page_source\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            contents_div = soup.find(name=\"div\", attrs={\"class\":\"evaluation_review\"})\n",
        "\n",
        "            # 별점을 가져옵니다.\n",
        "            rates = contents_div.find_all(name=\"em\", attrs={\"class\":\"num_rate\"})\n",
        "\n",
        "            # 리뷰를 가져옵니다.\n",
        "            reviews = contents_div.find_all(name=\"p\", attrs={\"class\":\"txt_comment\"})\n",
        "\n",
        "            for rate, review in zip(rates, reviews):\n",
        "                row = [rate.text[0], review.find(name=\"span\").text]\n",
        "                series = pd.Series(row, index=df.columns)\n",
        "                df = df.append(series, ignore_index=True)\n",
        "        except:\n",
        "            break    \n",
        "driver.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "5V6dZ8Mh97f0",
        "outputId": "a8137497-1767-47ca-def1-6d82c313f192"
      },
      "source": [
        "# 4점 이상의 리뷰는 긍정 리뷰, 3점 이하의 리뷰는 부정 리뷰로 평가합니다.\n",
        "df['y'] = df['score'].apply(lambda x: 1 if float(x) > 3 else 0)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(133, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>review</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>레어한 아이템이 많은 건 아니다 다 어디서 본거긴 하지만 가격이 몇백원 정도 더 싸...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>다양한 비건음식들이 많았어요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  score                                             review  y\n",
              "0     5                                                     1\n",
              "1     5  레어한 아이템이 많은 건 아니다 다 어디서 본거긴 하지만 가격이 몇백원 정도 더 싸...  1\n",
              "2     5                                                     1\n",
              "3     5                                                     1\n",
              "4     4                                    다양한 비건음식들이 많았어요  1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbNtK7s3_MeA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
